{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_BXCpyOZktO"
      },
      "outputs": [],
      "source": [
        "##Importing librabries for Exploratory data analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "SbGutG-Z13HF",
        "outputId": "56479752-ab29-4a6d-f069-89f33d494b11"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-075ceff34147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##Read a sheet in excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Case Study Data.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CraftBeer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Case Study Data.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Whiskey\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Case Study Data.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"WhiteWine\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 ext = inspect_excel_format(\n\u001b[0;32m-> 1192\u001b[0;31m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m                 )\n\u001b[1;32m   1194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     with get_handle(\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     ) as handle:\n\u001b[1;32m   1073\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Case Study Data.xlsx'"
          ]
        }
      ],
      "source": [
        "##Read a sheet in excel file\n",
        "df1 = pd.read_excel('Case Study Data.xlsx', sheet_name=\"CraftBeer\")\n",
        "df2 = pd.read_excel('Case Study Data.xlsx', sheet_name=\"Whiskey\")\n",
        "df3 = pd.read_excel('Case Study Data.xlsx', sheet_name=\"WhiteWine\")\n",
        "\n",
        "##Assigning it to another variable so that we can have the original one\n",
        "df4 = df1\n",
        "df5 = df2\n",
        "df6 = df3\n",
        "\n",
        "##Print all three sheet header\n",
        "print(df4.head())\n",
        "print(df5.head())\n",
        "print(df6.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWtZVtmxDZ8_"
      },
      "outputs": [],
      "source": [
        "##Lets check the data\n",
        "df1.info()\n",
        "df2.info()\n",
        "df3.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiq0Niz9nnCu"
      },
      "source": [
        "There is no null value here hence we don't need to remove any rows in any columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x--iAM8V4pAm"
      },
      "outputs": [],
      "source": [
        "## Combining Year and Month columns into single column and considering day as 1 for each month\n",
        "df4['Date'] = pd.to_datetime(df4[['Year', 'Month']].assign(DAY=1))\n",
        "print(df4.head())\n",
        "df5['Date'] = pd.to_datetime(df5[['Year', 'Month']].assign(DAY=1))\n",
        "print(df5.head())\n",
        "df6['Date'] = pd.to_datetime(df6[['Year', 'Month']].assign(DAY=1))\n",
        "print(df6.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFTDW9uUoCLu"
      },
      "source": [
        "Keeping Year and Month column only for one data frame because it will be easy to pivot the data using Year and Month number after joining all three data frames into single data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnJobso0DshY"
      },
      "outputs": [],
      "source": [
        "#Lets drop the month and Year columns\n",
        "df4.drop(columns=['Month','Year'],axis=1,inplace=True)\n",
        "df5.drop(columns=['Month','Year'],axis=1,inplace=True)\n",
        "print(df4.head())\n",
        "print(df5.head())\n",
        "print(df6.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM-WFQupocq8"
      },
      "source": [
        "Renaming the Relative interest column in all the data frame so that it will have unique name while joining the data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8wYtjPE7T9C"
      },
      "outputs": [],
      "source": [
        "##Renaming the column name for all three data frame\n",
        "df4.rename(columns={'Relative Interest':'Demand_CraftBeer'},inplace=True)\n",
        "df5.rename(columns={'Relative Interest':'Demand_Whiskey'},inplace=True)\n",
        "df6.rename(columns={'Relative Interest':'Demand_WhiteWine'},inplace=True)\n",
        "print(df4.head())\n",
        "print(df5.head())\n",
        "print(df6.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxmv_8CCoxTR"
      },
      "source": [
        "Merging all three data frame into single data frame so that it will be helpful for performing Exploratory Data Analysis and Visualization purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn5_EL2P_Axu"
      },
      "outputs": [],
      "source": [
        "##Join all three data frame into single data frame so that we can easy perform Exploratory Data Analysis\n",
        "df7 = pd.merge(df4,df5,on='Date',how='left')\n",
        "df8 = pd.merge(df6,df7,on='Date',how='left')\n",
        "df8.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ74S2zKqMmo"
      },
      "source": [
        "\\Moving Date column into index column for performing better Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDs_aCPWGyLR"
      },
      "outputs": [],
      "source": [
        "##Moving date column into index column so that we can assume assingn them into index function\n",
        "df8.set_index('Date', inplace=True)\n",
        "df8.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHknmiNCqDX0"
      },
      "source": [
        "Now the data is ready to perform, Lets check the data now before performing EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4uUefbCHeaO"
      },
      "outputs": [],
      "source": [
        "##Lets Check the datatype and its info\n",
        "print(df8.info())\n",
        "print(df8.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTH6oSG-Y8pQ"
      },
      "source": [
        "**Performing Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2kazQ67pWiw"
      },
      "outputs": [],
      "source": [
        "##Lets keep the data into new data frame \n",
        "df9 = df8\n",
        "df9.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q4mR7SCndun"
      },
      "outputs": [],
      "source": [
        "##adding line chart\n",
        "df10=df9.drop(columns=['Month','Year'],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpCgD2Czv0Ns"
      },
      "outputs": [],
      "source": [
        "df10.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ydzaz8U9ssEf"
      },
      "outputs": [],
      "source": [
        "df9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-yLPBSrvA0-"
      },
      "outputs": [],
      "source": [
        "##Let visualize on yearly basis how the interest of each brand varies\n",
        "Interest_on_year_WW = df9.groupby(\"Year\")[\"Demand_WhiteWine\"].mean()\n",
        "Interest_on_year_CB = df9.groupby(\"Year\")[\"Demand_CraftBeer\"].mean()\n",
        "Interest_on_year_WS = df9.groupby(\"Year\")[\"Demand_Whiskey\"].mean()\n",
        "print(Interest_on_year_WW)\n",
        "print(Interest_on_year_CB)\n",
        "print(Interest_on_year_WS)\n",
        "Interest_on_year_WW.plot(kind=\"line\", title = \"Average interest by Year\", x =\"Year\", y = \"Average interest\")\n",
        "Interest_on_year_CB.plot(kind=\"line\", title = \"Average interest by Year\", x =\"Year\", y = \"Average interest\")\n",
        "Interest_on_year_WS.plot(kind=\"line\", title = \"Average interest by Year\", x =\"Year\", y = \"Average interest\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the graph shows that the interet for whiskey and Craftbeer grows exponentially. Also there is a increase in interest for WhiteWine"
      ],
      "metadata": {
        "id": "KFhD3PIFybbL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHWr0IUcw6r5"
      },
      "outputs": [],
      "source": [
        "##Let visualize on Monthly basis how the interest of each brand varies\n",
        "Interest_on_month_WW = df9.groupby(\"Month\")[\"Demand_WhiteWine\"].mean()\n",
        "Interest_on_month_CB = df9.groupby(\"Month\")[\"Demand_CraftBeer\"].mean()\n",
        "Interest_on_month_WS = df9.groupby(\"Month\")[\"Demand_Whiskey\"].mean()\n",
        "print(Interest_on_month_WW)\n",
        "print(Interest_on_month_CB)\n",
        "print(Interest_on_month_WS)\n",
        "Interest_on_month_WW.plot(kind=\"line\", title = \"Average interest by Month\", x =\"Month\", y = \"Average interest\")\n",
        "Interest_on_month_CB.plot(kind=\"line\", title = \"Average interest by Month\", x =\"Month\", y = \"Average interest\")\n",
        "Interest_on_month_WS.plot(kind=\"line\", title = \"Average interest by month\", x =\"Month\", y = \"Average interest\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7xQdFkz8RPZ"
      },
      "source": [
        "The sals for White Wine and Whiskey was higher during year end compare to other months.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VX_U9m4SGaz"
      },
      "outputs": [],
      "source": [
        "##importing stat model\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "test_result=adfuller(df9['Demand_WhiteWine'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7o8YF8v-wIS"
      },
      "outputs": [],
      "source": [
        "##Creating a new function\n",
        "def adfuller_test(Demand_WhiteWine):\n",
        "    result=adfuller(Demand_WhiteWine)\n",
        "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
        "    for value,label in zip(result,labels):\n",
        "        print(label+' : '+str(value) )\n",
        "    if result[1] <= 0.05:\n",
        "        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n",
        "    else:\n",
        "        print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2j6TMcW_AYf"
      },
      "outputs": [],
      "source": [
        "##Testing each WhiteWine wheather it affect with seasonality or not\n",
        "adfuller_test(df8['Demand_WhiteWine'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPrsdn2q_iFu"
      },
      "source": [
        "Since the P-Value is greater than 0.05 then it has seasonaity pattern in it, we need to nullify them to perform Time series analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoBpLK9B_P07"
      },
      "outputs": [],
      "source": [
        "##Testing each CraftBeer wheather it affect with seasonality or not\n",
        "adfuller_test(df8['Demand_CraftBeer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Eu8VrWs_y6F"
      },
      "source": [
        "Since the P-Value is greaster than 0.05 then it has seasonaity pattern in it, we need to nullify them to perform Time series analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FGf-rt5_ZfZ"
      },
      "outputs": [],
      "source": [
        "##Testing each Whiskey wheather it affect with seasonality or not\n",
        "adfuller_test(df8['Demand_Whiskey'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxRBrbJG_6zK"
      },
      "source": [
        "Since the P-Value is less than 0.05 then doesn't have any seasonaity which means we can perform time series analysis with this column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRwxGtnBfcTc"
      },
      "outputs": [],
      "source": [
        "##copying data frame to another one\n",
        "df11 = df8\n",
        "df12 = df8\n",
        "df13 = df8\n",
        "df12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1ZteeGraTZd"
      },
      "outputs": [],
      "source": [
        "##Nullifying the seasonality for WhiteWine\n",
        "df11['Demand_WhiteWine'].shift(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL-LFkpAbzdV"
      },
      "outputs": [],
      "source": [
        "##Lets calculate for 1st order differencing\n",
        "df11['Demand_WhiteWine 12th Difference'] = df11['Demand_WhiteWine'] - df11['Demand_WhiteWine'].shift(12)\n",
        "df11['Demand_WhiteWine 12th Difference'].plot()\n",
        "df11.head(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3x8pu3_dDu0"
      },
      "outputs": [],
      "source": [
        "##Lets drop NA and check for the stationary\n",
        "adfuller_test(df11['Demand_WhiteWine 12th Difference'].dropna())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O48BrB1whJlN"
      },
      "source": [
        "Since the P-vaue is less than 0.05 we can tell now that data is stationary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZQspqRCgGof"
      },
      "outputs": [],
      "source": [
        "##Again calling same data frame\n",
        "df12['Demand_CraftBeer'].shift(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TLYJzK_ghrz"
      },
      "outputs": [],
      "source": [
        "##Lets calculate for 12th order differencing for craftBeer\n",
        "df12['Demand 1st Difference'] = df12['Demand_CraftBeer'] - df12['Demand_CraftBeer'].shift(1)\n",
        "df12['Demand 1st Difference'].plot()\n",
        "df12.head(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioGkuD4ygwt0"
      },
      "outputs": [],
      "source": [
        "##Lets drop NA and check for the stationary\n",
        "adfuller_test(df12['Demand 1st Difference'].dropna())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1ZNuM8QhuSV"
      },
      "source": [
        "Since the P-vaue is less than 0.05 we can tell now that data is stationary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk6I9iP1hwPJ"
      },
      "outputs": [],
      "source": [
        "##Lets calculate the lags for both the case using Partical Autocorrelation method\n",
        "##Lets import model also\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "fig = sm.graphics.tsa.plot_acf(df11['Demand_WhiteWine 12th Difference'].iloc[13:],lags=28,ax=ax1)\n",
        "ax2 = fig.add_subplot(212)\n",
        "fig = sm.graphics.tsa.plot_pacf(df11['Demand_WhiteWine 12th Difference'].iloc[13:],lags=28,ax=ax2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G65IdGilo4jk"
      },
      "outputs": [],
      "source": [
        "##Lets calculate the lags for both the case using Partical Autocorrelation method\n",
        "##Lets import model also\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "fig = sm.graphics.tsa.plot_acf(df12['Demand 1st Difference'].iloc[13:],lags=28,ax=ax1)\n",
        "ax2 = fig.add_subplot(212)\n",
        "fig = sm.graphics.tsa.plot_pacf(df12['Demand 1st Difference'].iloc[13:],lags=28,ax=ax2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LJz20YQ1kbo"
      },
      "outputs": [],
      "source": [
        "## Fitting SARIMA model to WhiteWine\n",
        "model_WW=sm.tsa.statespace.SARIMAX(df11.iloc[0:60,[2]],order=(2,1,4),seasonal_order=(2,1,4,6))\n",
        "results_WW=model_WW.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIhDF1eK2l48"
      },
      "outputs": [],
      "source": [
        "df11['Predict']=results_WW.predict(start=60,end=72,dynamic=True)\n",
        "df11[['Demand_WhiteWine','Predict']].plot(figsize=(12,8))\n",
        "ww_test = df11['Demand_WhiteWine'].iloc[60:72]\n",
        "ww_predict = df11['Predict'].iloc[60:72]\n",
        "ww_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoD_Cs0JndfQ"
      },
      "outputs": [],
      "source": [
        "## Calculate the error value to verfiy the model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_ww = mean_squared_error(ww_test,ww_predict,squared=False)\n",
        "mse_ww"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzU3LDm8pMoY"
      },
      "source": [
        "Since the error doesn't show that big we can say that it is good fit for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOTNswew8jZl"
      },
      "outputs": [],
      "source": [
        "##Lets Predict for next 1 year\n",
        "predict_future_WW=results_WW.predict(start=72,end=83,dynamic=True)\n",
        "print(predict_future_WW)\n",
        "plt.plot(df11.index,df11[['Demand_WhiteWine']].max(axis=1))\n",
        "plt.plot(predict_future_WW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S6Lesg7pPyf"
      },
      "source": [
        "** Lets do the same for Craftbeer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Enqev8WT20lT"
      },
      "outputs": [],
      "source": [
        "## Fitting model to SARIMA to Craft Beer\n",
        "model=sm.tsa.statespace.SARIMAX(df11['Demand_CraftBeer'],order=(1,1,1),seasonal_order=(1,1,1,12))\n",
        "result=model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEwPgcB33EOT"
      },
      "outputs": [],
      "source": [
        "df11['Predict']=result.predict(start=60,end=72,dynamic=True)\n",
        "df11[['Demand_CraftBeer','Predict']].plot(figsize=(12,8))\n",
        "CB_test = df11['Demand_CraftBeer'].iloc[60:72]\n",
        "CB_predict = df11['Predict'].iloc[60:72]\n",
        "CB_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWOzXIraqAY4"
      },
      "outputs": [],
      "source": [
        "## Calculate the error value to verfiy the model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_cb = mean_squared_error(CB_test,CB_predict,squared=False)\n",
        "mse_cb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtL1lGlJrYeg"
      },
      "source": [
        "Since the error doesn't show that big we can say that it is good fit for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsePBbqi8-g_"
      },
      "outputs": [],
      "source": [
        "##Lets Predict for next 1 year\n",
        "predict_future_CB=result.predict(start=72,end=83,dynamic=True)\n",
        "print(predict_future_CB)\n",
        "predict_future_CB.plot()\n",
        "df11['Demand_CraftBeer'].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0cgD1iU3atG"
      },
      "source": [
        "For Whisky"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iwond7RuI5l"
      },
      "outputs": [],
      "source": [
        "df10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1rZyqCRuiCr"
      },
      "outputs": [],
      "source": [
        "##Lets calculate the lags for both the case using Partical Autocorrelation method\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "fig = sm.graphics.tsa.plot_acf(df10['Demand_Whiskey'],lags=28,ax=ax1)\n",
        "ax2 = fig.add_subplot(212)\n",
        "fig = sm.graphics.tsa.plot_pacf(df10['Demand_Whiskey'],lags=28,ax=ax2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAmpEyEE6Kwk"
      },
      "outputs": [],
      "source": [
        "##Fitting the data\n",
        "model=sm.tsa.statespace.SARIMAX(df10['Demand_Whiskey'],order=(1,0,4),seasonal_order=(1,0,4,6))\n",
        "results_W=model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY7CzSrZ-Aj-"
      },
      "outputs": [],
      "source": [
        "##Checking model for whiskey\n",
        "df10['Predict']=results_W.predict(start=60,end=72,dynamic=True)\n",
        "df10[['Demand_Whiskey','Predict']].plot(figsize=(12,8))\n",
        "W_test = df10['Demand_Whiskey'].iloc[60:72]\n",
        "W_predict = df10['Predict'].iloc[60:72]\n",
        "W_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hqhUvYrUy9H"
      },
      "outputs": [],
      "source": [
        "## Calculate the error value to verfiy the model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_w = mean_squared_error(W_test,W_predict,squared=False)\n",
        "mse_w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysNHH69TjSua"
      },
      "outputs": [],
      "source": [
        "##Lets Predict for next 1 year\n",
        "predict_future_W=results_W.predict(start=72,end=83,dynamic=True)\n",
        "print(predict_future_W)\n",
        "predict_future_W.plot()\n",
        "df10['Demand_Whiskey'].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets perform another model : Seasonal Naive Baseline"
      ],
      "metadata": {
        "id": "aSCHfo5GxxnM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1-aiuE6m0IY"
      },
      "outputs": [],
      "source": [
        "for i in range(60,72):\n",
        "  df10.iloc[[i],3]=df10.iloc[[i-12],[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR3Mu5QEnykA"
      },
      "outputs": [],
      "source": [
        "df10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_uQMdxgnttG"
      },
      "outputs": [],
      "source": [
        "test_w = df10.iloc[60:72,[2]]\n",
        "test_w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSRxf51WnRHM"
      },
      "outputs": [],
      "source": [
        "predict_w = df10.iloc[60:72,[3]]\n",
        "predict_w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY4O_SRIogv5"
      },
      "outputs": [],
      "source": [
        "## Calculate the error value to verfiy the model\n",
        "mse_w = mean_squared_error(predict_w,test_w,squared=False)\n",
        "mse_w"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}